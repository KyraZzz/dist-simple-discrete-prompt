{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prompting.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt-based learning"
      ],
      "metadata": {
        "id": "EGSXXopgD17q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers"
      ],
      "metadata": {
        "id": "RrihLWeJHGGt"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "CodUfJDzHK2L"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompting Class\n",
        "Here is the class definition for Prompting"
      ],
      "metadata": {
        "id": "gY9tUJ2WEJQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForMaskedLM , AutoTokenizer\n",
        "class Prompting(object):\n",
        "  \"\"\" doc string \n",
        "   This class helps us to implement\n",
        "   Prompt-based Learning Model\n",
        "  \"\"\"\n",
        "  def __init__(self, **kwargs):\n",
        "    \"\"\" constructor \n",
        "    model: path to a Pre-trained language model form HuggingFace Hub\n",
        "    tokenizer: path to tokenizer if different tokenizer is used, otherwise leave it empty\n",
        "    \"\"\"\n",
        "    model_path=kwargs['model']\n",
        "    tokenizer_path= kwargs['model']\n",
        "    if \"tokenizer\" in kwargs.keys():\n",
        "      tokenizer_path= kwargs['tokenizer']\n",
        "    self.model = AutoModelForMaskedLM.from_pretrained(model_path)\n",
        "    self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "  def prompt_pred(self,text):\n",
        "    \"\"\"\n",
        "      Provide a text including a [MASK]. It supports single MASK token. \n",
        "      If more [MASK]ed tokens are given, it takes the first one.\n",
        "    \"\"\"\n",
        "    tokenized_text = self.tokenizer.tokenize(text)\n",
        "    indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
        "    tokens_tensor = torch.tensor([indexed_tokens])\n",
        "    # take the first masked token\n",
        "    mask_pos=tokenized_text.index(\"[MASK]\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      outputs = self.model(tokens_tensor)\n",
        "      predictions = outputs[0]\n",
        "    values, indices=torch.sort(predictions[0, mask_pos],  descending=True)\n",
        "    result=list(zip(tokenizer.convert_ids_to_tokens(indices), values))\n",
        "    self.scores_dict={a:b for a,b in result}\n",
        "    return result\n",
        "\n",
        "  def compute_tokens_prob(self, text, token1, token2):\n",
        "    \"\"\"\n",
        "    Compute the activations for given two tokens\n",
        "    \"\"\"\n",
        "    _=self.prompt_pred(text)\n",
        "    score1= self.scores_dict[token1] if token1 in self.scores_dict.keys() else 0\n",
        "    score2= self.scores_dict[token2] if token2 in self.scores_dict.keys() else 0\n",
        "    return {token1:score1, token2:score2}\n"
      ],
      "metadata": {
        "id": "oW_TsjAlc7Q2"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I take Turkish LM here, you can choose any other model. "
      ],
      "metadata": {
        "id": "5e4LgLhmFIR1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompting= Prompting(model=\"dbmdz/bert-base-turkish-cased\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T698UBNks760",
        "outputId": "4c9d0475-c541-4526-abf9-7d8bee941d77"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at dbmdz/bert-base-turkish-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Producing the predicted tokens"
      ],
      "metadata": {
        "id": "GWBBUoqCFUiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Çok keyif almadım filmden\"\n",
        "propmt=\", çünkü [MASK] idi.\"\n",
        "prompted= text + propmt\n",
        "prompting.prompt_pred(prompted)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REugyrnAtDTH",
        "outputId": "57db385d-1207-4dea-89c2-373035be7719"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gereksiz', tensor(8.3082)),\n",
              " ('kötü', tensor(8.2386)),\n",
              " ('sıkıcı', tensor(8.0629)),\n",
              " ('eski', tensor(7.8365)),\n",
              " ('saçma', tensor(7.7022)),\n",
              " ('berbat', tensor(7.5442)),\n",
              " ('iğrenç', tensor(7.5263)),\n",
              " ('yeni', tensor(7.4843)),\n",
              " ('eğlenceli', tensor(7.4627)),\n",
              " ('güzel', tensor(7.4235))]"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Çok keyif aldım filmden\"\n",
        "propmt=\", çünkü [MASK] idi.\"\n",
        "prompted= text + propmt\n",
        "prompting.prompt_pred(prompted)[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n23xEqxDgA9",
        "outputId": "135c5a87-ba10-4fec-d284-0d933f5f7fcc"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('harika', tensor(8.9176)),\n",
              " ('güzel', tensor(8.7036)),\n",
              " ('eğlenceli', tensor(8.6776)),\n",
              " ('muhteşem', tensor(8.5812)),\n",
              " ('mükemmel', tensor(8.3756)),\n",
              " ('iyi', tensor(7.8504)),\n",
              " ('komik', tensor(7.8444)),\n",
              " ('keyifli', tensor(7.6584)),\n",
              " ('akıcı', tensor(7.5700)),\n",
              " ('süper', tensor(7.5630))]"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Producing the results for  a pair of neg/pos words"
      ],
      "metadata": {
        "id": "Y56NnjdNFZJ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Çok keyif almadım filmden\"\n",
        "propmt=\", çünkü [MASK] idi.\"\n",
        "prompted= text + propmt\n",
        "prompting.compute_tokens_prob(prompted, \"gereksiz\", \"harika\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Og1uFMJVtq5E",
        "outputId": "8d07a048-fbfa-4715-89b1-ce718d5206af"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gereksiz': tensor(8.3082), 'harika': tensor(7.0045)}"
            ]
          },
          "metadata": {},
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Çok keyif aldım filmden\"\n",
        "prompted= text + propmt\n",
        "prompting.compute_tokens_prob(prompted, \"gereksiz\", \"harika\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRM6AH_FDKsC",
        "outputId": "3f49dd6f-3b8c-4f66-9801-4218df74c79a"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'gereksiz': tensor(6.8251), 'harika': tensor(8.9176)}"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Learning"
      ],
      "metadata": {
        "id": "V-7vHaV_GG_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "IGU_3E-CBp84"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}